{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tacotron 2 inference code \n",
        "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import libraries and setup matplotlib"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install librosa"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: librosa in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.10.0.post2)\nRequirement already satisfied: pooch<1.7,>=1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (1.6.0)\nRequirement already satisfied: joblib>=0.14 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (1.2.0)\nRequirement already satisfied: lazy-loader>=0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (0.2)\nRequirement already satisfied: msgpack>=1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (1.0.5)\nRequirement already satisfied: decorator>=4.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: audioread>=2.1.9 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (3.0.0)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (1.23.5)\nRequirement already satisfied: typing-extensions>=4.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (4.4.0)\nRequirement already satisfied: scikit-learn>=0.20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (1.2.0)\nRequirement already satisfied: soundfile>=0.12.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: scipy>=1.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (1.10.0)\nRequirement already satisfied: soxr>=0.3.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (0.3.4)\nRequirement already satisfied: numba>=0.51.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from librosa) (0.56.4)\nRequirement already satisfied: importlib-metadata in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (5.2.0)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (61.2.0)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (0.39.1)\nRequirement already satisfied: appdirs>=1.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pooch<1.7,>=1.0->librosa) (2.28.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa) (3.11.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "import sys\n",
        "sys.path.append('waveglow/')\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT, STFT\n",
        "from audio_processing import griffin_lim\n",
        "from train import load_model\n",
        "from text import text_to_sequence\n",
        "from denoiser import Denoiser"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2023-03-29 08:18:02.308071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-03-29 08:18:21.489352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-03-29 08:18:21.489471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-03-29 08:18:21.489483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1679947658281
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data, figsize=(16, 4)):\n",
        "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
        "                       interpolation='none')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1679947658455
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup hparams"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = create_hparams()\n",
        "hparams.sampling_rate = 22050"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1679947658573
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load model from checkpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoint_final\"\n",
        "model = load_model(hparams)\n",
        "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
        "_ = model.cuda().eval()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Tacotron2:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([160, 512]) from checkpoint, the shape in current model is torch.Size([148, 512]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_final\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(hparams)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39meval()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Tacotron2:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([160, 512]) from checkpoint, the shape in current model is torch.Size([148, 512])."
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1679947670724
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load WaveGlow for mel2audio synthesis and denoiser"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "waveglow_path = 'waveglow_256channels.pt'\n",
        "waveglow = torch.load(waveglow_path)['model']\n",
        "waveglow.cuda().eval()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "denoiser = Denoiser(waveglow)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679947663305
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare text input"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Waveglow is really awesome!\"\n",
        "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "sequence = torch.autograd.Variable(\n",
        "torch.from_numpy(sequence)).cuda().long()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679947663518
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decode text input and plot results"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
        "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "           alignments.float().data.cpu().numpy()[0].T))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1679947663532
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Synthesize audio from spectrogram using WaveGlow"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
        "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679947663544
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (Optional) Remove WaveGlow bias"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "audio_denoised = denoiser(audio, strength=0.01)[:, 0]\n",
        "ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679947663556
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}